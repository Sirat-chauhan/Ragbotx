

# ğŸ¤– RagBotX

### Advanced RAG Chatbot with GraphRAG & Persistent Chat Memory

**100% Local â€¢ Fully Private â€¢ Powered by Ollama**

RagBotX is a fully offline Retrieval-Augmented Generation (RAG) chatbot that lets you upload documents and ask intelligent, contextual questions â€” all without sending data to external APIs.

Built with Python, Streamlit, FAISS, LangChain, and Ollama.

---

## ğŸš€ Why RagBotX?

Most RAG systems stop at vector search.

RagBotX goes further:

* ğŸ” Hybrid Retrieval (Vector + Reranking)
* ğŸŒ GraphRAG (Knowledge Graphâ€“enhanced reasoning)
* ğŸ§  Chat Memory (Multi-turn awareness)
* ğŸ¯ HyDE Query Expansion (Improved recall)
* ğŸ”’ 100% Offline & Private
* âš¡ Fast, lightweight, and configurable

Everything runs locally using Ollama.

---

# âœ¨ Features

## ğŸ“‚ Document Upload

* Upload **PDF**, **DOCX**, or **TXT**
* Automatic chunking & indexing

## ğŸ” Hybrid Retrieval Pipeline

* FAISS vector search
* Neural reranking
* Improved semantic precision

## ğŸŒ GraphRAG

* Builds a lightweight Knowledge Graph
* Expands context using graph relationships
* Enhances deep document understanding

## ğŸ§  Persistent Chat Memory

* Remembers previous conversation turns
* Maintains contextual continuity

## ğŸ¯ HyDE Query Expansion

* Generates hypothetical answers
* Uses them to improve document retrieval quality

## ğŸ”„ Dual Mode Operation

* **RAG Mode** â†’ Context-aware document Q&A
* **Chat Mode** â†’ General AI conversation

## ğŸ›ï¸ Fully Customizable

* Model selection
* Temperature control
* Max retrieved contexts
* Toggle HyDE / Reranking / GraphRAG

---

# ğŸ–¥ï¸ How It Works

```
User Query
   â†“
HyDE Expansion (optional)
   â†“
FAISS Retrieval
   â†“
Neural Reranking (optional)
   â†“
GraphRAG Context Expansion (optional)
   â†“
Chat Memory Injection
   â†“
Ollama LLM Response
```

All computation happens locally.

No cloud. No tracking. No API keys.

---

# ğŸ“¦ Installation

## 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/siratchauhan/RagBotX.git
cd RagBotX
```

## 2ï¸âƒ£ Create Virtual Environment

### Windows

```bash
python -m venv venv
venv\Scripts\activate
```

### Mac/Linux

```bash
python3 -m venv venv
source venv/bin/activate
```

## 3ï¸âƒ£ Install Dependencies

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

---

## 4ï¸âƒ£ Install Ollama & Pull Models

Download Ollama:
[https://ollama.ai](https://ollama.ai)

Then pull required models:

```bash
ollama pull qwen2:0.5b
ollama pull nomic-embed-text
```

You can change models later in the `.env` file.

---

## 5ï¸âƒ£ Configure Environment

Create a `.env` file in the project root:

```
DEFAULT_MODEL=qwen2:0.5b
EMBEDDINGS_MODEL=nomic-embed-text
ENABLE_HYDE=true
ENABLE_RERANKING=true
ENABLE_GRAPH_RAG=true
TEMPERATURE=0.7
MAX_CONTEXTS=3
```

---

## 6ï¸âƒ£ Start Ollama

```bash
ollama serve
```

---

## 7ï¸âƒ£ Launch RagBotX

```bash
streamlit run app.py
```

---

# ğŸ§ª Use Cases

* ğŸ“š Research assistant
* ğŸ“„ Legal / contract analysis
* ğŸ¢ Private company knowledge base
* ğŸ“ Study companion
* ğŸ” Air-gapped environments

---

# ğŸ›£ï¸ Roadmap

* Suggested follow-up questions
* Graph visualization UI
* Export Knowledge Graph as JSON
* Support for alternative vector databases
* Advanced RAG pipelines (Basic vs Graph-Enhanced)
* Multi-document collection management

---

# ğŸ§  Tech Stack

* Python
* Streamlit
* FAISS
* LangChain
* Ollama

---

# ğŸ¤ Contributing

Pull requests, ideas, and feedback are welcome!

If you find this project useful, consider giving it a â­

